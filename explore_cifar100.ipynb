{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjoshi/anaconda3/envs/distillation/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sjoshi/anaconda3/envs/distillation/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): GroupNorm(128, 128, eps=1e-05, affine=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): GroupNorm(128, 128, eps=1e-05, affine=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): GroupNorm(128, 128, eps=1e-05, affine=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=2048, out_features=128, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from networks import ConvNet\n",
    "from utils import get_default_convnet_setting\n",
    "net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
    "model = ConvNet(channel=3, num_classes=128, net_depth=net_depth, net_act=net_act, net_width=net_width, net_norm=net_norm, net_pooling=net_pooling)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def ColourDistortion(s=1.0):\n",
    "    # s is the strength of color distortion.\n",
    "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
    "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
    "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
    "    return color_distort\n",
    "\n",
    "\n",
    "CACHED_MEAN_STD = {\n",
    "    'cifar10': ((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    'cifar100': ((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "    'stl10': ((0.4467, 0.4398, 0.4066), (0.2603, 0.2566, 0.2713)),\n",
    "    'imagenet': ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    'mnist':((0.1307), (0.3081))\n",
    "}\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        #transforms.RandomResizedCrop((32,32), interpolation=Image.BICUBIC),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        ColourDistortion(s=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*CACHED_MEAN_STD[\"cifar100\"])\n",
    "    ])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(*CACHED_MEAN_STD[\"cifar100\"])])\n",
    "dataset = torchvision.datasets.CIFAR10(\"/data\", train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = torch.load(\"/home/sjoshi/mtt-distillation/target_rep/CIFAR100/train_rep_r50_128_dim.pt\", map_location=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftLabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dataset, label_tensor, subset_idx=None):\n",
    "        super().__init__()\n",
    "        self.img_dataset = img_dataset\n",
    "        self.label_tensor = label_tensor\n",
    "        assert len(self.img_dataset) == len(self.label_tensor)\n",
    "        self.subset_idx = subset_idx\n",
    "        if self.subset_idx is None:\n",
    "            self.subset_idx = range(len(self.img_dataset))\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        idx = self.subset_idx[i]\n",
    "        return (self.img_dataset[idx][0], self.label_tensor[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.subset_idx)\n",
    "    \n",
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_tensor, label_tensor, subset_idx=None):\n",
    "        super().__init__()\n",
    "        self.img_tensor = img_tensor\n",
    "        self.label_tensor = label_tensor\n",
    "        assert len(self.img_tensor) == len(self.label_tensor)\n",
    "        self.subset_idx = subset_idx\n",
    "        if self.subset_idx is None:\n",
    "            self.subset_idx = range(len(self.img_tensor))\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        idx = self.subset_idx[i]\n",
    "        return (self.img_tensor[idx], self.label_tensor[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.subset_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dset 5000\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import pickle \n",
    "\n",
    "with open(\"/home/sjoshi/mtt-distillation/sorted_idx/sorted_indices_CIFAR100.pkl\", \"rb\") as f:\n",
    "    loss_ranking = pickle.load(f)\n",
    "    \n",
    "with open(\"/home/sjoshi/mtt-distillation/init/cifar100/random_50ipc.pkl\", \"rb\") as f:\n",
    "    subset_idx = pickle.load(f)\n",
    "#subset_idx = random.sample(range(50000), 50000)\n",
    "# with open(\"/data/file_transfer/cifar100-0.02-kmeans-sas-indices.pkl\", \"rb\") as f:\n",
    "#     subset_idx = pickle.load(f)\n",
    "# with open(\"/home/sjoshi/mtt-distillation/init/cifar100/random_10ipc.pkl\", \"rb\") as f:\n",
    "#     subset_idx = pickle.load(f)\n",
    "dst_train = SoftLabelDataset(dataset, labels_all, subset_idx)\n",
    "print(\"length of dset\", len(dst_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_init = torch.load(\"/home/sjoshi/mtt-distillation/logged_files/CIFAR100/2024-01-15_16:17:53None/images_1.pt\")\n",
    "labels_init = torch.load(\"/home/sjoshi/mtt-distillation/logged_files/CIFAR100/2024-01-15_16:17:53None/labels_1.pt\")\n",
    "# images_syn = torch.load(\"/home/sjoshi/krrst_orig/results/2024-01-0814:46:15.950178_CIFAR100_random_5000_new_arch/x_syn_final.pt\")\n",
    "# labels_syn = torch.load(\"/home/sjoshi/krrst_orig/results/2024-01-0814:46:15.950178_CIFAR100_random_5000_new_arch/y_syn_final.pt\")\n",
    "\n",
    "images_best = torch.load(\"/home/sjoshi/mtt-distillation/logged_files/CIFAR100/2024-01-15_16:17:53None/images_100.pt\")\n",
    "labels_best = torch.load(\"/home/sjoshi/mtt-distillation/logged_files/CIFAR100/2024-01-15_16:17:53None/labels_100.pt\")\n",
    "# # images_init = torch.load(\"/home/sjoshi/krrst_orig/results/2024-01-0814:47:42.550038_CIFAR100_high_loss_5000_new_arch/x_syn_initial.pt\")\n",
    "# # labels_init = torch.load(\"/home/sjoshi/krrst_orig/results/2024-01-0814:47:42.550038_CIFAR100_high_loss_5000_new_arch/y_syn_initial.pt\")\n",
    "# # # images_syn = torch.load(\"/home/sjoshi/krrst_orig/results/2024-01-0814:47:42.550038_CIFAR100_high_loss_5000_new_arch/x_syn_final.pt\")\n",
    "# # # labels_syn = torch.load(\"/home/sjoshi/krrst_orig/results/2024-01-0814:47:42.550038_CIFAR100_high_loss_5000_new_arch/y_syn_final.pt\")\n",
    "\n",
    "\n",
    "dst_train = TensorDataset(images_init, labels_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(tensor_img):\n",
    "    tensor_img = tensor_img.clone()\n",
    "    rescaled_imgs = torch.empty_like(tensor_img)\n",
    "    mean, std = CACHED_MEAN_STD[\"cifar100\"]\n",
    "    for i, (t, m, s) in enumerate(zip(tensor_img, mean, std)):\n",
    "        rescaled_imgs[i] = t.mul(s).add(m)\n",
    "    rescaled_imgs[rescaled_imgs < 0] = 0\n",
    "    rescaled_imgs[rescaled_imgs > 1] = 1\n",
    "    display(transforms.ToPILImage()(rescaled_imgs).resize((96,96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x7F754B2477F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x7F7556A6AF10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0078)\n"
     ]
    }
   ],
   "source": [
    "i = 13\n",
    "rescale(images_init[i])\n",
    "rescale(images_best[i])\n",
    "print(torch.mean(torch.abs(images_best[i] - images_init[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "from networks import ConvNet\n",
    "from utils import get_default_convnet_setting\n",
    "trainloader = torch.utils.data.DataLoader(dst_train, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
    "device = torch.device(\"cuda:5\")\n",
    "net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
    "model = ConvNet(channel=3, num_classes=128, net_depth=net_depth, net_act=net_act, net_width=net_width, net_norm=net_norm, net_pooling=net_pooling)\n",
    "print(len(dst_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "class ChangeLabels(Dataset):\n",
    "    def __init__(self, dataset, new_labels):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset \n",
    "        self.new_labels = new_labels\n",
    "        \n",
    "    def __getitem__(self, index: Any) -> Any:\n",
    "        return self.dataset[index][0], self.new_labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_256 = torch.load(\"/home/sjoshi/mtt-distillation/target_rep/CIFAR100/train_rep_kmeans_256_plabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = ChangeLabels(dataset, kmeans_256)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre-training: 100%|██████████| 20/20 [00:16<00:00,  1.19it/s, loss: 0.5243302727699279]\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F \n",
    "from tqdm import tqdm, trange\n",
    "from utils import ParamDiffAug\n",
    "\n",
    "dsa_param = ParamDiffAug()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "pbar = trange(20, desc=\"pre-training\")\n",
    "for epoch in pbar:\n",
    "    loss_avg, num_exp = 0, 0\n",
    "    for datum in trainloader:\n",
    "        img = datum[0].float().to(device)\n",
    "        lab = datum[1].float().to(device)\n",
    "        #lab = datum[1].to(device)\n",
    "        #indices = indices.to(device)\n",
    "        \n",
    "        n_b = img.shape[0]\n",
    "\n",
    "        output = model(img)\n",
    "        \n",
    "        loss = criterion(output, lab)\n",
    "                \n",
    "        loss_avg += loss.item()*n_b\n",
    "        num_exp += n_b\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    pbar.set_postfix_str(f\"loss: {loss_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch.utils.data import Dataset \n",
    "class DatasetWithIndices(Dataset):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __getitem__(self, index: Any) -> Any:\n",
    "        return index, self.dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "metric_trainloader = torch.utils.data.DataLoader(DatasetWithIndices(dataset), batch_size=128, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre-training:   0%|          | 0/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metric_trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     10\u001b[0m     loss_avg, num_exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, datum \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetric_trainloader\u001b[49m:\n\u001b[1;32m     12\u001b[0m         img \u001b[38;5;241m=\u001b[39m datum[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m         n_b \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metric_trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from tqdm import tqdm \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.24195 momentum=0.9, weight_decay=1e-3)\n",
    "pbar = tqdm(range(80), desc=\"pre-training\")\n",
    "for epoch in pbar:\n",
    "    loss_avg, num_exp = 0, 0\n",
    "    for idx, datum in metric_trainloader:\n",
    "        img = datum[0].float().to(device)\n",
    "        n_b = img.shape[0]\n",
    "        student_z = model(img)\n",
    "        \n",
    "        student_dist = F.cosine_similarity(student_z.unsqueeze(1), student_z.unsqueeze(0), dim=2)\n",
    "        teacher_z = labels_all[idx].to(device)\n",
    "        teacher_dist = F.cosine_similarity(teacher_z.unsqueeze(1), teacher_z.unsqueeze(0), dim=2)\n",
    "        loss = torch.log(torch.sum(torch.exp(student_dist - teacher_dist)))\n",
    "\n",
    "        loss_avg += loss.item()\n",
    "        num_exp += n_b\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    pbar.set_postfix_str(f\"loss: {loss_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding: 100%|██████████| 196/196 [00:02<00:00, 74.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 2048])\n",
      "torch.Size([50000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset \n",
    "import random\n",
    "\n",
    "untrained_model = ConvNet(channel=3, num_classes=128, net_depth=net_depth, net_act=net_act, net_width=net_width, net_norm=net_norm, net_pooling=net_pooling)\n",
    "untrained_model = untrained_model.to(device)\n",
    "Z = []\n",
    "Y = []\n",
    "random.seed(0)\n",
    "random_subset = list(random.sample(range(50000), 50000))\n",
    "clf_cifar100 = Subset(torchvision.datasets.CIFAR100(\"/data\", transform=transform), indices=random_subset)\n",
    "clf_dataloader = torch.utils.data.DataLoader(clf_cifar100, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(clf_dataloader, desc=\"encoding\"):\n",
    "        Z.append(model.features(X.to(device)).view(-1, 2048))\n",
    "        #Z.append(model(X.to(device)))\n",
    "        Y.append(y.to(device))\n",
    "Z = torch.cat(Z, dim=0)\n",
    "Y = torch.cat(Y, dim=0)\n",
    "print(Z.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clf(X, y, representation_dim, num_classes, device, reg_weight=1e-3, iter=500):\n",
    "    print('\\nL2 Regularization weight: %g' % reg_weight)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    n_lbfgs_steps = iter\n",
    "\n",
    "    # Should be reset after each epoch for a completely independent evaluation\n",
    "    clf = nn.Linear(representation_dim, num_classes).to(device)\n",
    "    clf_optimizer = optim.LBFGS(clf.parameters())\n",
    "    clf.train()\n",
    "\n",
    "    t = tqdm(range(n_lbfgs_steps), desc='Loss: **** | Train Acc: ****% ', bar_format='{desc}{bar}{r_bar}')\n",
    "    for _ in t:\n",
    "        def closure():\n",
    "            clf_optimizer.zero_grad()\n",
    "            raw_scores = clf(X)\n",
    "            loss = criterion(raw_scores, y)\n",
    "            loss += reg_weight * clf.weight.pow(2).sum()\n",
    "            loss.backward()\n",
    "\n",
    "            _, predicted = raw_scores.max(1)\n",
    "            correct = predicted.eq(y).sum().item()\n",
    "\n",
    "            t.set_description('Loss: %.3f | Train Acc: %.3f%% ' % (loss, 100. * correct / y.shape[0]))\n",
    "\n",
    "            return loss\n",
    "\n",
    "        clf_optimizer.step(closure)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def test_clf(testloader, device, net, clf, feature=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net.eval()\n",
    "    clf.eval()\n",
    "    test_clf_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    acc_per_point = []\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(enumerate(testloader), total=len(testloader), desc='Loss: **** | Test Acc: ****% ',\n",
    "                 bar_format='{desc}{bar}{r_bar}')\n",
    "        for batch_idx, (inputs, targets) in t:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            representation = None\n",
    "            if feature:\n",
    "                representation = net.features(inputs).view(-1, 2048)\n",
    "            else:\n",
    "                #representation = net.features(inputs).view(-1, 2048)\n",
    "                representation = net(inputs)\n",
    "            # test_repr_loss = criterion(representation, targets)\n",
    "            raw_scores = clf(representation)\n",
    "            clf_loss = criterion(raw_scores, targets)\n",
    "            test_clf_loss += clf_loss.item()\n",
    "            _, predicted = raw_scores.max(1)\n",
    "            total += targets.size(0)\n",
    "            acc_per_point.append(predicted.eq(targets))\n",
    "            correct += acc_per_point[-1].sum().item()\n",
    "            t.set_description('Loss: %.3f | Test Acc: %.3f%% ' % (test_clf_loss / (batch_idx + 1), 100. * correct / total))\n",
    "            \n",
    "    acc = 100. * correct / total\n",
    "    return acc, torch.cat(acc_per_point, dim=0).cpu().numpy()\n",
    "\n",
    "def top5accuracy(output, target, topk=(5,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        print(correct)\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_test = torchvision.datasets.CIFAR100(\"/data\", train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(cifar100_test, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2 Regularization weight: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.972 | Train Acc: 65.562% : ██████████| 100/100 [00:17<00:00,  5.65it/s]\n"
     ]
    }
   ],
   "source": [
    "clf = train_clf(Z, Y, Z.shape[1], 100, device, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.240 | Test Acc: 44.480% : ██████████| 40/40 [00:00<00:00, 60.74it/s]\n"
     ]
    }
   ],
   "source": [
    "acc, acc_per_point = test_clf(testloader, device, model, clf, feature=True)\n",
    "#acc, acc_per_point = test_clf(clf_dataloader, device, model, clf, embed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_subset = random.sample(range(50000), 1000)\n",
    "clf = train_clf(labels_all.to(device)[random_subset], torch.tensor([dataset[i][1] for i in range(50000)]).to(device)[random_subset], labels_all.shape[1], 100, device, iter=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.load(\"/home/sjoshi/mtt-distillation/target_rep/CIFAR100/test_rep_r50_128_dim.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding: 100%|██████████| 40/40 [00:00<00:00, 48.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset \n",
    "import random\n",
    "\n",
    "test_Z = []\n",
    "random.seed(0)\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(testloader, desc=\"encoding\"):\n",
    "        #test_Z.append(model.features(X.to(device)).view(-1, 2048))\n",
    "        test_Z.append(model(X.to(device)))\n",
    "test_Z = torch.cat(test_Z, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2048) must match the size of tensor b (128) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_mse_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50000\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     train_mse_losses\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mZ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2048) must match the size of tensor b (128) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "train_mse_losses = []\n",
    "for i in range(50000):\n",
    "    train_mse_losses.append(torch.norm(Z[i].cpu() - labels_all[i]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_test_labels = [cifar100_test[i][1] for i in range(len(cifar100_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_per_point = []\n",
    "with torch.no_grad():\n",
    "    for i in range(10000):\n",
    "        pred = torch.argmax(model(test_labels[i].unsqueeze(dim=0))[0]).item()\n",
    "        test_acc_per_point.append(pred == cifar100_test_labels[i])\n",
    "print(np.mean(test_acc_per_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4672\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "test_acc_per_point = []\n",
    "with torch.no_grad():\n",
    "    for i in range(10000):\n",
    "        pred = torch.argmax(model(cifar100_test[i][0].unsqueeze(dim=0).to(device))[0]).item()\n",
    "        test_acc_per_point.append(pred == cifar100_test_labels[i])\n",
    "print(np.mean(test_acc_per_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "with open(\"/home/sjoshi/mtt-distillation/sorted_idx/cifar100_r34_fscores_epoch_200.pkl\", \"rb\") as f:\n",
    "    loaded = pickle.load(f)\n",
    "    fscore = np.zeros(50000)\n",
    "    fscore[np.array(loaded[\"indices\"])] = loaded[\"forgetting counts\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [i for i in range(10000) if acc_per_point[i]]\n",
    "wrong = [i for i in range(10000) if not acc_per_point[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.84it/s]\n"
     ]
    }
   ],
   "source": [
    "test_representations = []\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(testloader):\n",
    "        test_representations.append(model.features(X.to(device)).view(-1, 2048))\n",
    "    test_representations = torch.cat(test_representations, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    syn_representations = model.features(images_best.to(device)).view(-1, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"init/cifar100/random_50ipc_2.pkl\", \"rb\") as f:\n",
    "    syn_idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_syn = {}\n",
    "for i in range(100):\n",
    "    partition_syn[i] = []\n",
    "for i, j in enumerate(syn_idx):\n",
    "    partition_syn[dataset[j][1]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:40<00:00, 99.80it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_to_same_syn = []\n",
    "sim_to_diff_syn = []\n",
    "for i in tqdm(range(10000)):\n",
    "    test_label = cifar100_test_labels[i]\n",
    "    sim_to_same_syn.append(torch.mean(test_representations[i:i+1] @ syn_representations[partition_syn[test_label]].T).item())\n",
    "    curr_diff_sim = []\n",
    "    for j in range(100):\n",
    "        if j == test_label:\n",
    "            continue\n",
    "        curr_diff_sim.append(torch.mean(test_representations[i:i+1] @ syn_representations[partition_syn[j]].T).item())\n",
    "    sim_to_diff_syn.append(np.mean(curr_diff_sim))\n",
    "sim_to_same_syn = np.array(sim_to_same_syn)\n",
    "sim_to_diff_syn = np.array(sim_to_diff_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535.5304243683565 50.099814491966114\n",
      "493.80743034756665 37.59873036435433\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(sim_to_same_syn[correct]), np.std(sim_to_same_syn[correct]))\n",
    "print(np.mean(sim_to_same_syn[wrong]), np.std(sim_to_same_syn[wrong]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458.11616229930604\n",
      "459.4665628371746\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(sim_to_diff_syn[correct]))\n",
    "print(np.mean(sim_to_diff_syn[wrong]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(left_image, right_image):\n",
    "    # Ensure both images have the same shape\n",
    "    assert left_image.shape == right_image.shape, \"Images must have the same shape\"\n",
    "\n",
    "    # Get the width of the images\n",
    "    width = left_image.shape[2]\n",
    "\n",
    "    # Split the images into left and right halves\n",
    "    left_half = left_image[:, :, :width // 2]\n",
    "    right_half = right_image[:, :, width // 2:]\n",
    "\n",
    "    # Concatenate the left and right halves to create the combined image\n",
    "    combined_image = torch.cat([left_half, right_half], dim=2)\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_acc(class_num):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in partition_syn[class_num]:\n",
    "        for j in partition_syn[class_num]:\n",
    "            if i == j:\n",
    "                continue \n",
    "            total += 1\n",
    "            interpolated_image = combine_images(images_best[i], images_best[j]).unsqueeze(dim=0).to(device)\n",
    "            with torch.no_grad():\n",
    "                if torch.argmax(clf(model.features(interpolated_image).view(-1, 2048))[0]).item() == class_num:\n",
    "                    correct += 1\n",
    "                    \n",
    "    return correct / total * 100\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.75952658321724"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated_accs = [interpolate_acc(i) for i in range(100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distillation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
